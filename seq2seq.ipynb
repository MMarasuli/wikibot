{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tohpedo/wikibot/blob/seq2seq/seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRXlwTfbROJq"
      },
      "source": [
        "# imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlqYTLFkLRBw",
        "outputId": "893a61cc-3f9b-4efc-e2bd-75093e9a679a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM5bxWWTRXZE"
      },
      "source": [
        "# base\n",
        "\n",
        "base = pd.read_csv(\"/content/drive/MyDrive/Squad/database.csv\")[:5000]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-EqgbgtRaX8"
      },
      "source": [
        "# define function to clean the text \n",
        "\n",
        "def clean_text(text):\n",
        "\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"\\n\", \"\",  text)\n",
        "    text = re.sub(r\"[-()]\", \"\", text)\n",
        "    text = re.sub(r\"\\.\", \" . \", text)\n",
        "    text = re.sub(r\"\\!\", \" ! \", text)\n",
        "    text = re.sub(r\"\\?\", \" ? \", text)\n",
        "    text = re.sub(r\"\\,\", \" , \", text)\n",
        "    text = re.sub(r\"\\\"\", \" \\\" \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am\", text)\n",
        "    text = re.sub(r\"he's\", \"he is\", text)\n",
        "    text = re.sub(r\"she's\", \"she is\", text)\n",
        "    text = re.sub(r\"it's\", \"it is\", text)\n",
        "    text = re.sub(r\"that's\", \"that is\", text)\n",
        "    text = re.sub(r\"what's\", \"that is\", text)\n",
        "    text = re.sub(r\"where's\", \"where is\", text)\n",
        "    text = re.sub(r\"how's\", \"how is\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"won't\", \"will not\", text)\n",
        "    text = re.sub(r\"can't\", \"cannot\", text)\n",
        "    text = re.sub(r\"n't\", \" not\", text)\n",
        "    text = re.sub(r\"n'\", \"ng\", text)\n",
        "    text = re.sub(r\"'bout\", \"about\", text)\n",
        "    text = re.sub(r\"'til\", \"until\", text)\n",
        "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
        "\n",
        "    \n",
        "    return text"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKL1zQbVvcIf"
      },
      "source": [
        "# **Base Processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFGQOiwqRd7v"
      },
      "source": [
        "# base processing \n",
        "\n",
        "base = base.dropna()\n",
        "\n",
        "# defining lenghts of q's and a's\n",
        "\n",
        "q_text = []\n",
        "\n",
        "for line in base.question:\n",
        "    q_text.append(clean_text(line))\n",
        "\n",
        "q_len = []\n",
        "for line in q_text:\n",
        "    q_len.append(len(line.split()))\n",
        "\n",
        "max_q_length = max(q_len)\n",
        "\n",
        "a_text = []\n",
        "for line in base.text:\n",
        "    a_text.append(clean_text(line))\n",
        "\n",
        "a_len = []\n",
        "for line in a_text:\n",
        "    a_len.append(len(line.split()))\n",
        "\n",
        "# plus two due to tokens\n",
        "max_a_length = max(a_len) + 2\n",
        "\n",
        "# adding tokens to answers\n",
        "for i in range(len(a_text)):\n",
        "    a_text[i]  = \"<BOS> \" + a_text[i] + \" <EOS>\"\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_OiNMKkRiup"
      },
      "source": [
        "# vocab and tokenizing\n",
        "# making vocab\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "vocab_size = 10000\n",
        "tokenizer = Tokenizer(num_words = vocab_size, lower=False, filters=\"\")\n",
        "tokenizer.fit_on_texts(q_text + a_text)\n",
        "dictionary = tokenizer.word_index\n",
        "\n",
        "word2token = {}\n",
        "token2word = {}\n",
        "\n",
        "for k, v in dictionary.items():\n",
        "    if v < vocab_size:\n",
        "        word2token[k] = v\n",
        "        token2word[v] = k\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "vocab_size = len(word2token) + 1\n",
        "\n",
        "# tokenizing sentences\n",
        "\n",
        "encoder_seq = tokenizer.texts_to_sequences(q_text)\n",
        "decoder_seq = tokenizer.texts_to_sequences(a_text)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvxGxQUGRmdF"
      },
      "source": [
        "# padding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "encoder_input = pad_sequences(encoder_seq, \n",
        "                              maxlen = max_q_length,\n",
        "                              padding = \"post\",\n",
        "                              truncating= \"post\")\n",
        "\n",
        "decoder_input = pad_sequences(decoder_seq, \n",
        "                              maxlen = max_a_length,\n",
        "                              padding = \"post\",\n",
        "                              truncating= \"post\")\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HU5yUpOBRoo7"
      },
      "source": [
        "# formating decoder output\n",
        "for i in range(len(decoder_seq)):\n",
        "    decoder_seq[i] =  decoder_seq[i][1:]\n",
        "    \n",
        "# pad with 0\n",
        "padded_answers = pad_sequences(decoder_seq,\n",
        "                               maxlen = max_a_length,\n",
        "                               padding = \"post\")\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6PIKSr_RsT5"
      },
      "source": [
        "#deleting non-necessary variables\n",
        "del(a_len, a_text, decoder_seq, dictionary, encoder_seq, i, k, line, q_len, q_text,  v)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfMDH7nsr-QC"
      },
      "source": [
        "decoder_output = to_categorical(padded_answers, vocab_size)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKX09iVGr_-4"
      },
      "source": [
        "#deleting non-necessary variables\n",
        "del(padded_answers)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAassb7wvjtL"
      },
      "source": [
        "# **Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcQu8WEZRu7E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56901f0f-a06d-471f-d7f9-1e9fc7845298"
      },
      "source": [
        "# =============================================================================\n",
        "# Model\n",
        "# =============================================================================\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input\n",
        "\n",
        "# encoder will be used to capture space-dependent relations between words from the questions\n",
        "# about 200 neurons needed \n",
        "\n",
        "emedding_size = 1024\n",
        "enc_inputs = Input(shape=(None,))\n",
        "enc_embeding = Embedding(vocab_size, emedding_size, mask_zero=True)\n",
        "enc_embeding = enc_embeding(enc_inputs)\n",
        "enc_lstm = LSTM(emedding_size,  return_state=True)\n",
        "enc_outputs, h, c = enc_lstm(enc_embeding)\n",
        "enc_states = [h, c]\n",
        "\n",
        "# decoder will be used to capture space-dependent relations between words from the answers using encoder's internal state as a context\n",
        "\n",
        "dec_inputs = Input(shape=(None,))\n",
        "dec_embedding = Embedding(vocab_size, emedding_size, mask_zero=True)\n",
        "dec_embedding = dec_embedding(dec_inputs)\n",
        "dec_lstm = LSTM(emedding_size, return_state=True, return_sequences=True)\n",
        "dec_outputs, _, _ = dec_lstm(dec_embedding, initial_state = enc_states)\n",
        "\n",
        "# decoder is connected to the output Dense layer\n",
        "dec_dense = Dense(vocab_size, activation = \"softmax\")\n",
        "output = dec_dense(dec_outputs)\n",
        "\n",
        "model = Model([enc_inputs, dec_inputs], output)\n",
        "# output of this network will look like this:\n",
        "# y_true = [0.05, 0.95, 0...]\n",
        "# and expected one-hot encoded output like this:\n",
        "# y_pred = [0, 1, 0...]\n",
        "model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"acc\"])\n",
        "model.summary()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 1024)   7738368     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 1024)   7738368     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 1024), (None 8392704     embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 1024), 8392704     embedding_1[0][0]                \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 7557)   7745925     lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 40,008,069\n",
            "Trainable params: 40,008,069\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhE4MesvvT5Z"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-sj-ub6vBK4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc6991e8-0bac-4a01-ab41-91580e980239"
      },
      "source": [
        "!pip install pyyaml h5py  # Required to save models in HDF5 format"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkIMbTllucYP"
      },
      "source": [
        "# creating checkpoints\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "checkpoint_path = \"/content/drive/MyDrive/Squad/training_4/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "# This may generate warnings related to saving the state of the optimizer.\n",
        "# These warnings (and similar warnings throughout this notebook)\n",
        "# are in place to discourage outdated usage, and can be ignored."
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr91muWIwxJg"
      },
      "source": [
        "# **The Actual Bot part**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5BOqbbGgP0Y"
      },
      "source": [
        "use only while training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh-MxfRNu8YI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "544996f9-3d25-43d6-8e04-5f696f65109f"
      },
      "source": [
        "# fitting the model\n",
        "model.fit([encoder_input, decoder_input],\n",
        "          decoder_output,\n",
        "          batch_size = 32,\n",
        "          epochs = 80,\n",
        "          callbacks = [cp_callback])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "146/146 [==============================] - 20s 74ms/step - loss: 0.5081 - acc: 0.4366\n",
            "\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 2/80\n",
            "146/146 [==============================] - 11s 75ms/step - loss: 0.4168 - acc: 0.4645\n",
            "\n",
            "Epoch 00002: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 3/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 0.3857 - acc: 0.4698\n",
            "\n",
            "Epoch 00003: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 4/80\n",
            "146/146 [==============================] - 11s 75ms/step - loss: 0.3588 - acc: 0.4814\n",
            "\n",
            "Epoch 00004: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 5/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 0.3286 - acc: 0.4964\n",
            "\n",
            "Epoch 00005: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 6/80\n",
            "146/146 [==============================] - 11s 75ms/step - loss: 0.2971 - acc: 0.5172\n",
            "\n",
            "Epoch 00006: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 7/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 0.2659 - acc: 0.5471\n",
            "\n",
            "Epoch 00007: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 8/80\n",
            "146/146 [==============================] - 11s 75ms/step - loss: 0.2370 - acc: 0.5917\n",
            "\n",
            "Epoch 00008: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 9/80\n",
            "146/146 [==============================] - 11s 75ms/step - loss: 0.2128 - acc: 0.6351\n",
            "\n",
            "Epoch 00009: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 10/80\n",
            "146/146 [==============================] - 11s 75ms/step - loss: 0.1838 - acc: 0.6832\n",
            "\n",
            "Epoch 00010: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 11/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 0.1622 - acc: 0.7186\n",
            "\n",
            "Epoch 00011: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 12/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 0.1468 - acc: 0.7407\n",
            "\n",
            "Epoch 00012: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 13/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 0.1231 - acc: 0.7649\n",
            "\n",
            "Epoch 00013: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 14/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 0.1034 - acc: 0.7912\n",
            "\n",
            "Epoch 00014: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 15/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 0.0852 - acc: 0.8229\n",
            "\n",
            "Epoch 00015: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 16/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 0.0667 - acc: 0.8660\n",
            "\n",
            "Epoch 00016: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 17/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 0.0494 - acc: 0.9050\n",
            "\n",
            "Epoch 00017: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 18/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 0.0349 - acc: 0.9374\n",
            "\n",
            "Epoch 00018: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 19/80\n",
            "146/146 [==============================] - 11s 77ms/step - loss: 0.0246 - acc: 0.9549\n",
            "\n",
            "Epoch 00019: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 20/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 0.0172 - acc: 0.9667\n",
            "\n",
            "Epoch 00020: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 21/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 0.0123 - acc: 0.9755\n",
            "\n",
            "Epoch 00021: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 22/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 0.0087 - acc: 0.9833\n",
            "\n",
            "Epoch 00022: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 23/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 0.0060 - acc: 0.9904\n",
            "\n",
            "Epoch 00023: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 24/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 0.0048 - acc: 0.9943\n",
            "\n",
            "Epoch 00024: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 25/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 0.0043 - acc: 0.9950\n",
            "\n",
            "Epoch 00025: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 26/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 0.0027 - acc: 0.9970\n",
            "\n",
            "Epoch 00026: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 27/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 0.0021 - acc: 0.9979\n",
            "\n",
            "Epoch 00027: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 28/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 0.0012 - acc: 0.9987\n",
            "\n",
            "Epoch 00028: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 29/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 7.5142e-04 - acc: 0.9995\n",
            "\n",
            "Epoch 00029: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 30/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 5.9179e-04 - acc: 0.9996\n",
            "\n",
            "Epoch 00030: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 31/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 5.0505e-04 - acc: 0.9996\n",
            "\n",
            "Epoch 00031: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 32/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 4.5790e-04 - acc: 0.9996\n",
            "\n",
            "Epoch 00032: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 33/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 4.0318e-04 - acc: 0.9997\n",
            "\n",
            "Epoch 00033: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 34/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 3.4175e-04 - acc: 0.9996\n",
            "\n",
            "Epoch 00034: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 35/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 3.0699e-04 - acc: 0.9998\n",
            "\n",
            "Epoch 00035: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 36/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 2.9826e-04 - acc: 0.9996\n",
            "\n",
            "Epoch 00036: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 37/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 2.7742e-04 - acc: 0.9996\n",
            "\n",
            "Epoch 00037: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 38/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 2.5552e-04 - acc: 0.9997\n",
            "\n",
            "Epoch 00038: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 39/80\n",
            "146/146 [==============================] - 11s 75ms/step - loss: 2.5498e-04 - acc: 0.9996\n",
            "\n",
            "Epoch 00039: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 40/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 2.2408e-04 - acc: 0.9997\n",
            "\n",
            "Epoch 00040: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 41/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 2.0549e-04 - acc: 0.9997\n",
            "\n",
            "Epoch 00041: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 42/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 2.0754e-04 - acc: 0.9997\n",
            "\n",
            "Epoch 00042: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 43/80\n",
            "146/146 [==============================] - 11s 75ms/step - loss: 1.6751e-04 - acc: 0.9998\n",
            "\n",
            "Epoch 00043: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 44/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 1.7090e-04 - acc: 0.9997\n",
            "\n",
            "Epoch 00044: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 45/80\n",
            "146/146 [==============================] - 11s 75ms/step - loss: 1.6653e-04 - acc: 0.9997\n",
            "\n",
            "Epoch 00045: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 46/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 1.5770e-04 - acc: 0.9997\n",
            "\n",
            "Epoch 00046: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 47/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 1.6714e-04 - acc: 0.9997\n",
            "\n",
            "Epoch 00047: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 48/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 1.5061e-04 - acc: 0.9998\n",
            "\n",
            "Epoch 00048: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 49/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 1.3492e-04 - acc: 0.9997\n",
            "\n",
            "Epoch 00049: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 50/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 1.3582e-04 - acc: 0.9997\n",
            "\n",
            "Epoch 00050: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 51/80\n",
            "146/146 [==============================] - 11s 77ms/step - loss: 1.0422e-04 - acc: 0.9998\n",
            "\n",
            "Epoch 00051: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 52/80\n",
            "146/146 [==============================] - 11s 75ms/step - loss: 1.2346e-04 - acc: 0.9997\n",
            "\n",
            "Epoch 00052: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 53/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 1.1643e-04 - acc: 0.9997\n",
            "\n",
            "Epoch 00053: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 54/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 1.0881e-04 - acc: 0.9997\n",
            "\n",
            "Epoch 00054: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 55/80\n",
            "146/146 [==============================] - 11s 75ms/step - loss: 8.9213e-05 - acc: 0.9998\n",
            "\n",
            "Epoch 00055: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 56/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 9.6912e-05 - acc: 0.9998\n",
            "\n",
            "Epoch 00056: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 57/80\n",
            "146/146 [==============================] - 11s 75ms/step - loss: 9.5752e-05 - acc: 0.9997\n",
            "\n",
            "Epoch 00057: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 58/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 9.1267e-05 - acc: 0.9998\n",
            "\n",
            "Epoch 00058: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 59/80\n",
            "146/146 [==============================] - 11s 75ms/step - loss: 1.0583e-04 - acc: 0.9997\n",
            "\n",
            "Epoch 00059: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 60/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 9.0034e-05 - acc: 0.9998\n",
            "\n",
            "Epoch 00060: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 61/80\n",
            "146/146 [==============================] - 11s 75ms/step - loss: 9.3564e-05 - acc: 0.9997\n",
            "\n",
            "Epoch 00061: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 62/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 8.3106e-05 - acc: 0.9998\n",
            "\n",
            "Epoch 00062: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 63/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 9.4386e-05 - acc: 0.9997\n",
            "\n",
            "Epoch 00063: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 64/80\n",
            "146/146 [==============================] - 11s 75ms/step - loss: 7.3246e-05 - acc: 0.9998\n",
            "\n",
            "Epoch 00064: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 65/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 8.0715e-05 - acc: 0.9997\n",
            "\n",
            "Epoch 00065: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 66/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 7.9750e-05 - acc: 0.9997\n",
            "\n",
            "Epoch 00066: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 67/80\n",
            "146/146 [==============================] - 11s 75ms/step - loss: 8.3302e-05 - acc: 0.9997\n",
            "\n",
            "Epoch 00067: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 68/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 9.8854e-05 - acc: 0.9996\n",
            "\n",
            "Epoch 00068: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 69/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 7.3588e-05 - acc: 0.9998\n",
            "\n",
            "Epoch 00069: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 70/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 8.3770e-05 - acc: 0.9997\n",
            "\n",
            "Epoch 00070: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 71/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 8.1541e-05 - acc: 0.9997\n",
            "\n",
            "Epoch 00071: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 72/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 7.4891e-05 - acc: 0.9998\n",
            "\n",
            "Epoch 00072: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 73/80\n",
            "146/146 [==============================] - 11s 77ms/step - loss: 8.2963e-05 - acc: 0.9997\n",
            "\n",
            "Epoch 00073: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 74/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 6.4208e-05 - acc: 0.9997\n",
            "\n",
            "Epoch 00074: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 75/80\n",
            "146/146 [==============================] - 11s 77ms/step - loss: 6.7812e-05 - acc: 0.9997\n",
            "\n",
            "Epoch 00075: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 76/80\n",
            "146/146 [==============================] - 11s 77ms/step - loss: 5.3019e-05 - acc: 0.9998\n",
            "\n",
            "Epoch 00076: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 77/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 6.2344e-05 - acc: 0.9997\n",
            "\n",
            "Epoch 00077: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 78/80\n",
            "146/146 [==============================] - 11s 77ms/step - loss: 6.3324e-05 - acc: 0.9998\n",
            "\n",
            "Epoch 00078: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 79/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 7.4009e-05 - acc: 0.9997\n",
            "\n",
            "Epoch 00079: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n",
            "Epoch 80/80\n",
            "146/146 [==============================] - 11s 76ms/step - loss: 7.1632e-05 - acc: 0.9997\n",
            "\n",
            "Epoch 00080: saving model to /content/drive/MyDrive/Squad/training_3/cp.ckpt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f56fa127cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--xBppUjigLe"
      },
      "source": [
        "use once trained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJCIxKNAgAWL",
        "outputId": "8e168b69-1600-45a0-c174-d11b544f5878"
      },
      "source": [
        "# Loads the weights\n",
        "model.load_weights(checkpoint_path)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f56e80ecd90>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQEGpVJ0Q7jd"
      },
      "source": [
        "**BOT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mD3A50sZR6cz"
      },
      "source": [
        "# =============================================================================\n",
        "# Bot\n",
        "# =============================================================================\n",
        "\n",
        "def make_inference_models():\n",
        "    # two inputs for the state vectors returned by encoder\n",
        "    dec_state_input_h = Input(shape=(emedding_size,))\n",
        "    dec_state_input_c = Input(shape=(emedding_size,))\n",
        "    dec_states_inputs = [dec_state_input_h, dec_state_input_c]\n",
        "    # these state vectors are used as an initial state \n",
        "    # for LSTM layer in the inference decoder\n",
        "    # third input is the Embedding layer as explained above   \n",
        "    dec_outputs, h, c = dec_lstm(dec_embedding,\n",
        "                                    initial_state=dec_states_inputs)\n",
        "    dec_states = [h, c]\n",
        "    # Dense layer is used to return OHE predicted word\n",
        "    dec_outputs = dec_dense(dec_outputs)\n",
        "    dec_model = Model(\n",
        "        inputs=[dec_inputs] + dec_states_inputs,\n",
        "        outputs=[dec_outputs] + dec_states)\n",
        "   \n",
        "    # single encoder input is a question, represented as a sequence \n",
        "    # of integers padded with zeros\n",
        "    enc_model = Model(inputs=enc_inputs, outputs=enc_states)\n",
        "   \n",
        "    return enc_model, dec_model\n",
        "\n",
        "enc_model, dec_model = make_inference_models()\n",
        "\n",
        "def str_to_tokens(sentence: str):\n",
        "\n",
        "    sentence = clean_text(sentence)\n",
        "    words = sentence.lower().split()\n",
        "    tokens_list = list()\n",
        "    for current_word in words:\n",
        "        result = tokenizer.word_index.get(current_word, '')\n",
        "        if result != \"\":\n",
        "            tokens_list.append(result)\n",
        "    return pad_sequences([tokens_list],\n",
        "                         maxlen = max_q_length,\n",
        "                         padding = \"post\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIFUxqKBSGeN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 992
        },
        "outputId": "49646572-7576-49c3-f648-15772fee0e4f"
      },
      "source": [
        "# =============================================================================\n",
        "# chatting loop\n",
        "# =============================================================================\n",
        "\n",
        "for _ in range(20):\n",
        "    # encode the input sequence into state vectors\n",
        "    states_values = enc_model.predict(str_to_tokens(input(\"user : \")))\n",
        "    # start with a target sequence of size 1 - word 'start'   \n",
        "    empty_target_seq = np.zeros((1, 1))\n",
        "    empty_target_seq[0, 0] = tokenizer.word_index[\"<BOS>\"]\n",
        "    stop_condition = False\n",
        "    decoded_translation = \"\"\n",
        "    while not stop_condition:\n",
        "        # feed vectors and word for prediction\n",
        "        dec_outputs, h, c = dec_model.predict([empty_target_seq]\n",
        "                                              + states_values)         \n",
        "        # sample the next word using these predictions\n",
        "        sampled_word_index = np.argmax(dec_outputs[0, -1, :])\n",
        "        sampled_word = None\n",
        "        # append the sampled word to the target sequence\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if sampled_word_index == index:\n",
        "                if word != \"<EOS>\":\n",
        "                    decoded_translation += \" {}\".format(word)\n",
        "                sampled_word = word\n",
        "        # repeat until <EOS> or lenght\n",
        "        if sampled_word == \"<EOS>\" \\\n",
        "                or len(decoded_translation.split()) \\\n",
        "                > max_a_length:\n",
        "            stop_condition = True\n",
        "        # prepare next iteration\n",
        "        empty_target_seq = np.zeros((1, 1))\n",
        "        empty_target_seq[0, 0] = sampled_word_index\n",
        "        states_values = [h, c]\n",
        "    print(\"chatbot: \" + decoded_translation)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user : how old is beyonce\n",
            "chatbot:  69 180\n",
            "user : where is beyonce from\n",
            "chatbot:  europe and the new world\n",
            "user : how many grammys does beyonce have\n",
            "chatbot:  four octaves\n",
            "user : who is beyonce married to\n",
            "chatbot:  jay z\n",
            "user : does beyonce have kids\n",
            "chatbot:  september 2015\n",
            "user : how many kids does beyonce have\n",
            "chatbot:  four octaves\n",
            "user : when was chopin born\n",
            "chatbot:  1810\n",
            "user : who was chopin's mother?\n",
            "chatbot:  countess wodzińska\n",
            "user : who is the mother of chopin\n",
            "chatbot:  jay z\n",
            "user : what does chopin play\n",
            "chatbot:  flute and violin\n",
            "user : what does frederic chopin play?\n",
            "chatbot:  flute and violin\n",
            "user : who is steve wozniak\n",
            "chatbot:  alexander glazunov\n",
            "user : who is alexander glazunov\n",
            "chatbot:  link and zelda\n",
            "user : what did alexander glazunow do\n",
            "chatbot:  assassin\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \"\"\"\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-bc1c2846a269>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# encode the input sequence into state vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mstates_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"user : \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# start with a target sequence of size 1 - word 'start'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mempty_target_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}